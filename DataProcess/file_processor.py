"""
Single file processing logic for LLVM IR files
"""
import subprocess
import os
import logging
from typing import List, Optional, Tuple, Union
from transformers import PreTrainedTokenizerFast

from GraphBuilder.ddg_graph_builder import DataDependencyGraphBuilder
from GraphBuilder.cfg_graph_builder import CFGGraphBuilder
from Tokenizer.normalizer import normalize_file
from .processing_result import ProcessingResult


class FileProcessor:
    """Handles processing of individual LLVM IR files"""
    
    def __init__(self, 
                 tokenizer: PreTrainedTokenizerFast,
                 ddg_so_path: str,
                 purify_so_path: str,
                 cfg_so_path: str,
                 cleanup_temp_files: bool = True):
        self.tokenizer = tokenizer
        self.ddg_so_path = ddg_so_path
        self.purify_so_path = purify_so_path
        self.cfg_so_path = cfg_so_path
        self.cleanup_temp_files = cleanup_temp_files
        self.logger = logging.getLogger(__name__)
        
    def _opt_initial_purify(self, llvm_ir_path: str) -> Optional[str]:
        """Strip all metadata from LLVM IR using custom pass"""
        purified_file = os.path.splitext(llvm_ir_path)[0] + '_purified.ll'
        new_path = os.path.dirname(llvm_ir_path)
        
        try:
            cmd = [
                "opt",
                "-S",
                "-load-pass-plugin="+ self.purify_so_path,
                "--passes=strip-all-metadata",
                "-non-global-value-max-name-size=16384",
                os.path.basename(llvm_ir_path),
                "-o", os.path.basename(purified_file)
            ]

            p = subprocess.run(cmd, text=True, capture_output=True, cwd=new_path)
            stdout, stderr = p.stdout, p.stderr
            if p.returncode != 0:
                error_message = f"opt failed with return code {p.returncode}, stdout: {stdout}, stderr: {stderr}"
                self.logger.error(error_message)
                raise ValueError(error_message)
                
            if not os.path.exists(os.path.join(new_path, os.path.basename(purified_file))):
                error_message = f"Purified file was not created: {purified_file}"
                self.logger.error(error_message)
                raise ValueError(error_message)
                
            return os.path.join(new_path, os.path.basename(purified_file))
            
        except Exception as e:
            self.logger.error(f"Exception in metadata stripping for {llvm_ir_path}: {e}")
            return None
            
    def _opt_generate_ddg(self, purified_llvm_ir_path: str) -> Optional[Tuple[str, str]]:
        """Generate DDG using opt tool on purified IR"""
        instrumented_file = os.path.splitext(purified_llvm_ir_path)[0] + '_instrumented.ll'
        new_path = os.path.dirname(purified_llvm_ir_path)
        
        try:
            cmd = [
                "opt",
                "-load-pass-plugin=" + self.ddg_so_path,
                "-passes=dot-id-graph",
                "-non-global-value-max-name-size=16384",
                os.path.basename(purified_llvm_ir_path),
                "-S",
                "-o", os.path.basename(instrumented_file)
            ]

            p = subprocess.run(cmd, text=True, capture_output=True, cwd=new_path)
            stdout, stderr = p.stdout, p.stderr

            dot_file = None
            for line in stderr.splitlines():
                if "Writing ID-tagged graph to" in line:
                    dot_file = line.split("'")[1]
                    break
            else:
                self.logger.error("No dot file generated by opt, output is" f"{stdout} | stderr: {stderr}")
                return None
                    
            if dot_file is None:
                return None
                
            dot_file = os.path.join(new_path, dot_file)
            return instrumented_file, dot_file
            
        except Exception as e:
            self.logger.error(f"Exception in DDG generation for {purified_llvm_ir_path}: {e}")
            return None
            
    def _opt_generate_cfg(self, purified_llvm_ir_path: str) -> Optional[str]:
        """Generate CFG using opt tool on purified IR"""
        new_path = os.path.dirname(purified_llvm_ir_path)
        
        try:
            cmd = [
                "opt",
                "-load-pass-plugin=" + self.cfg_so_path,
                "-passes=dot-my-cfg",
                "-non-global-value-max-name-size=16384",
                os.path.basename(purified_llvm_ir_path),
                "-o", "/dev/null"
            ]

            p = subprocess.run(cmd, text=True, capture_output=True, cwd=new_path)
            stdout, stderr = p.stdout, p.stderr

            dot_file = None
            for line in stderr.splitlines():
                if "Write CFG to " in line:
                    dot_file = line.split("'")[1]
                    break
            else:
                self.logger.error("No dot file generated by opt, output is" f"{stdout} | stderr: {stderr}")
                return None
            
            if dot_file is None:
                return None
                
            return os.path.join(new_path, dot_file)
            
        except Exception as e:
            self.logger.error(f"Exception in CFG generation for {purified_llvm_ir_path}: {e}")
            return None
            
    def _generate_ddg(self, llvm_ir_path: str, purified_file: str) -> Union[None, List[Tuple[int, int, int, int]]]:
        """Generate DDG graph structure using purified IR"""
        result = self._opt_generate_ddg(purified_file)
        if result is None:
            return None
            
        instrumented_file, dot_file = result
        
        try:
            builder = DataDependencyGraphBuilder(self.tokenizer)
            ddg_graph = builder.generate_ddg_matrix(dot_file, instrumented_file, purified_file)
            return ddg_graph
        except Exception as e:
            self.logger.error(f"Error in DDG building for {llvm_ir_path}: {e}")
            return None
            
    def _generate_cfg(self, llvm_ir_path: str, purified_file: str) -> Union[None, List[Tuple[int, int, int, int, float]]]:
        """Generate CFG graph structure using purified IR"""
        dot_file = self._opt_generate_cfg(purified_file)
        if dot_file is None:
            return None
            
        try:
            builder = CFGGraphBuilder(self.tokenizer, purified_file, dot_file)
            cfg_graph = builder.build_cfg_edges()
            return cfg_graph
        except Exception as e:
            self.logger.error(f"Error in CFG building for {llvm_ir_path}: {e}")
            return None
            
    def _generate_token_ids(self, llvm_ir_path: str, purified_file: str) -> Optional[Tuple[List[int], List[int]]]:
        """Generate token IDs and attention mask using purified IR"""
        try:
            normalized_ir = normalize_file(purified_file)
            tokens = self.tokenizer(normalized_ir)
            return tokens['input_ids'], tokens['attention_mask']
        except Exception as e:
            self.logger.error(f"Error in tokenization for {llvm_ir_path}: {e}")
            return None
            
    def _cleanup_temp_files(self, temp_files: List[str]):
        """Clean up temporary files"""
        if not self.cleanup_temp_files:
            return
            
        for temp_file in temp_files:
            try:
                if temp_file and os.path.exists(temp_file):
                    os.remove(temp_file)
                    self.logger.debug(f"Cleaned up temporary file: {temp_file}")
            except Exception as e:
                self.logger.warning(f"Failed to clean up {temp_file}: {e}")
                
    def process_single_file(self, llvm_ir_path: str) -> ProcessingResult:
        """Process a single LLVM IR file"""
        temp_files = []
        
        try:
            # First, purify the IR by removing all metadata
            purified_file = self._opt_initial_purify(llvm_ir_path)
            if purified_file is None:
                return ProcessingResult(
                    file_path=llvm_ir_path,
                    success=False,
                    error_message="Failed to purify IR (remove metadata)"
                )
            
            temp_files.append(purified_file)
            
            # Generate DDG using purified IR
            ddg_graph = self._generate_ddg(llvm_ir_path, purified_file)
            
            # Generate CFG using purified IR
            cfg_graph = self._generate_cfg(llvm_ir_path, purified_file)
            
            # Generate tokens using purified IR
            token_result = self._generate_token_ids(llvm_ir_path, purified_file)
            input_ids, attention_mask = token_result if token_result else (None, None)
            
            success = ddg_graph is not None or cfg_graph is not None or input_ids is not None
            
            return ProcessingResult(
                file_path=llvm_ir_path,
                success=success,
                ddg_graph=ddg_graph,
                cfg_graph=cfg_graph,
                input_ids=input_ids,
                attention_mask=attention_mask
            )
            
        except Exception as e:
            return ProcessingResult(
                file_path=llvm_ir_path,
                success=False,
                error_message=str(e)
            )
        finally:
            self._cleanup_temp_files(temp_files)
